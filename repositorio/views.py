from django.conf import settings
from django.shortcuts import render, redirect
import fitz  # PyMuPDF
from django.views.generic.edit import UpdateView
from django.views.generic import CreateView, ListView, DetailView, DeleteView, View
from .models import Documento
from .forms import DocumentoForm
from django.http import HttpResponse, JsonResponse
from django.urls import reverse_lazy
from django.db.models import Q
import re
from collections import Counter
from repositorio.models import LineaInvestigacion
from django.utils.safestring import mark_safe
import json

from django.contrib.auth.mixins import LoginRequiredMixin
from django.contrib.auth import authenticate, login
from django.contrib.auth.forms import AuthenticationForm

def login_view(request):
    if request.method == 'POST':
        form = AuthenticationForm(request, data=request.POST)
        if form.is_valid():
            usuario = form.get_user()
            login(request, usuario)
            return redirect('principal')  # Usa el nombre de tu URL
    else:
        form = AuthenticationForm()
    return render(request, 'login.html', {'form': form})


import unicodedata

def normalizar(texto):
    """
    Convierte el texto a min√∫sculas y elimina acentos (tildes).
    """
    if not texto:
        return ""
    texto = texto.lower()
    return ''.join(
        c for c in unicodedata.normalize('NFD', texto)
        if unicodedata.category(c) != 'Mn'
    )

def principal(request):
    return render(request, 'principal.html')

def busqueda_ajax(request):
    query = request.GET.get('q', '')
    resultados = []

    if query:
        query_normalizado = normalizar(query)
        documentos = Documento.objects.all()

        for doc in documentos:
            if query_normalizado in normalizar(doc.titulo):
                resultados.append({
                    'id': doc.id,
                    'titulo': doc.titulo,
                    'autor' : doc.autor,
                    'director' : doc.director,
                    'metodologia' : doc.metodologia,
                })
            if len(resultados) >= 10:
                break

    return JsonResponse({'resultados': resultados})



def buscar_documentos(request):
    query = request.GET.get('q', '')
    resultados = []

    if query:
        query_normalizado = normalizar(query)
        documentos = Documento.objects.all()

        for doc in documentos:
            if (
                query_normalizado in normalizar(doc.titulo) or
                query_normalizado in normalizar(doc.autor or '') or
                query_normalizado in normalizar(doc.categoria or '')
            ):
                resultados.append(doc)

    return render(request, 'busqueda_documentos.html', {
        'resultados': resultados,
        'query': query
    })

def obtener_a√±os_disponibles():
    publicaciones = Documento.objects.values_list('publicacion', flat=True)
    a√±os = set()

    for pub in publicaciones:
        if pub:
            a√±o = detectar_a√±o(pub)
            if a√±o:
                a√±os.add(a√±o)
    
    return sorted(a√±os)

def resultados_busqueda_view(request):
    query = request.GET.get('q', '').strip()
    categoria_filtro = request.GET.get('categoria', '')
    linea_filtro = request.GET.get('linea', '')
    a√±o_filtro = request.GET.get('a√±o', '')

    # üîπ Obtener todos los a√±os disponibles (antes de filtrar)
    a√±os = Documento.objects.exclude(a√±o__isnull=True).values_list('a√±o', flat=True).distinct().order_by('-a√±o')

    # üîπ Obtener todos los documentos (sin filtros a√∫n)
    documentos = Documento.objects.all()

    if query:
        documentos = [doc for doc in documentos if normalizar(query) in normalizar(
            ' '.join([
                doc.titulo or '',
                doc.autor or '',
                doc.director or '',
                doc.metodologia or '',
                doc.categoria or '',
                ' '.join([li.nombre for li in doc.lineas_investigacion.all()])
            ])
        )]

    if categoria_filtro:
        documentos = [doc for doc in documentos if doc.categoria == categoria_filtro]
    
    if linea_filtro:
        documentos = [doc for doc in documentos if doc.lineas_investigacion.filter(nombre=linea_filtro).exists()]
    
    if a√±o_filtro:
        documentos = [doc for doc in documentos if str(doc.a√±o) == a√±o_filtro]

    categorias = Documento.objects.values_list('categoria', flat=True).distinct()
    lineas = LineaInvestigacion.objects.values_list('nombre', flat=True).distinct()

    return render(request, 'resultados_busqueda.html', {
        'query': query,
        'resultados': documentos,
        'categorias': categorias,
        'lineas': lineas,
        'a√±o_filtro': a√±o_filtro,
        'a√±os': a√±os,  # <- Esta lista s√≠ se va a mostrar al cargar la p√°gina
    })

LINEAS_INVESTIGACION = {
    "electronica": [
        "An√°lisis T√©cnica", "EduTech", "Experiencias ETIAE/MTIAE",
        "Productos ‚Äì Prototipos ‚Äì Tecnol√≥gicos", "Sistemas de Control", "Tecnolog√≠as Digitales"
    ],
    "diseno": [
        "An√°lisis T√©cnica", "Dise√±o de Prototipos", "Educaci√≥n en y con tecnolog√≠a",
        "Experiencias ETIAE/MTIAE", "Herramientas Digitales", "Monograf√≠as", "Propuesta Disciplinar"
    ],
    "tecnologia": [
        "An√°lisis T√©cnica", "Dise√±o de Prototipos", "Educaci√≥n en y con tecnolog√≠a",
        "Experiencias ETIAE/MTIAE", "Herramientas Digitales", "Monograf√≠as", "Propuesta Disciplinar"
    ]
}
def asegurar_lineas_investigacion():
    from .models import LineaInvestigacion
    for categoria, nombres in LINEAS_INVESTIGACION.items():
        for nombre in nombres:
            LineaInvestigacion.objects.get_or_create(nombre=nombre)

class DocumentoUpdateView(UpdateView):
    asegurar_lineas_investigacion()
    model = Documento
    form_class = DocumentoForm
    template_name = 'documento_editar.html'
    login_url = 'login'

    def get_success_url(self):
        return reverse_lazy('documento_detalle', kwargs={'pk': self.object.pk})

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        
        # Generar lista con id y nombre para cada l√≠nea
        linea_data = {}
        for categoria, nombres in LINEAS_INVESTIGACION.items():
            lineas = LineaInvestigacion.objects.filter(nombre__in=nombres)
            linea_data[categoria] = [
                {"id": linea.id, "nombre": linea.nombre} for linea in lineas
            ]
        
        context["linea_data"] = {
            k: mark_safe(json.dumps(v)) for k, v in linea_data.items()
        }
    
        return context

class DocumentoEliminarView(DeleteView):
    login_url = 'login'
    model = Documento
    template_name = 'documento_confirmar_eliminar.html' 
    
    def get_success_url(self):
        documento = self.get_object()
        return reverse_lazy(f"lic_{documento.categoria.lower()}") if documento.categoria else reverse_lazy('principal')

import requests
import tempfile
class DocumentoCreateView(CreateView):
    login_url = 'login'
    model = Documento
    form_class = DocumentoForm
    template_name = 'documento_form.html'

    def get_success_url(self):
        if self.object:
            if self.object.categoria == "electronica":
                return reverse_lazy('lic_electronica')
            elif self.object.categoria == "diseno":
                return reverse_lazy('lic_diseno')
            elif self.object.categoria == "tecnologia":
                return reverse_lazy('lic_tecnologia')
        return reverse_lazy('principal')
    
    def get_context_data(self, **kwargs):
        asegurar_lineas_investigacion()
        context = super().get_context_data(**kwargs)
        
        # Generar lista con id y nombre para cada l√≠nea
        linea_data = {}
        for categoria, nombres in LINEAS_INVESTIGACION.items():
            lineas = LineaInvestigacion.objects.filter(nombre__in=nombres)
            linea_data[categoria] = [
                {"id": linea.id, "nombre": linea.nombre} for linea in lineas
            ]
        
        context["linea_data"] = {
            k: mark_safe(json.dumps(v)) for k, v in linea_data.items()
        }
    
        return context

    def form_valid(self, form):
        documento = form.save(commit=False)
    
        archivo_pdf = None  # Ruta del PDF final (local o descargado)
    
        # üß© Si hay archivo subido localmente
        if documento.archivo:
            archivo_pdf = documento.archivo.path
    
        # üåê Si no hay archivo subido pero s√≠ hay enlace
        elif documento.enlace:
            try:
                response = requests.get(documento.enlace)
                if response.status_code == 200:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                        tmp_file.write(response.content)
                        archivo_pdf = tmp_file.name
                else:
                    print("‚ùå Error descargando el PDF desde el enlace.")
            except Exception as e:
                print("‚ùå Error en la descarga:", e)
    
        # üîç Si se obtuvo un archivo PDF de alguna forma
        if archivo_pdf:
            texto, num_paginas, ruta_pdf = extraer_texto(archivo_pdf)
            info_extraida = procesar_documento(archivo_pdf)
            if info_extraida is None:
                info_extraida = {}
    
            info_general = info_extraida.get("Informaci√≥n General", {})
            documento.a√±o = detectar_a√±o(texto)
            documento.titulo = info_general.get("T√çTULO", "No disponible")
            documento.autor = info_general.get("AUTOR(ES)", "No disponible")
            documento.director = info_general.get("DIRECTOR", "No registrado")
            documento.palabras_clave = info_general.get("PALABRAS CLAVE", "No disponibles")
            documento.unidad_patrocinante = info_general.get("UNIDAD PATROCINANTE", "No disponible")
            documento.publicacion = info_general.get("PUBLICACI√ìN", "No disponible")
            documento.descripcion = info_extraida.get("Descripci√≥n", "No disponible")
            documento.metodologia = info_extraida.get("Metodolog√≠a", "No disponible")
            documento.contenidos = info_extraida.get("Contenidos", "No disponible")
            documento.conclusiones = info_extraida.get("Conclusiones", "No disponible")
    
            fuentes = info_extraida.get("Fuentes", "No disponible")
            documento.fuentes = "\n".join(fuentes) if isinstance(fuentes, list) else fuentes
    
        # üéØ Guardar categor√≠a y l√≠neas
        lineas_ids = self.request.POST.getlist("lineas_investigacion")
        documento.categoria = form.cleaned_data['categoria']
        documento.save()
        documento.lineas_investigacion.set(lineas_ids)
    
        return redirect(self.get_success_url())
    
# Vistas de las licenciaturas
class DocumentoEView(ListView):
    model = Documento
    template_name = 'lic_electronica.html'
    context_object_name = 'object_list'

    def get_queryset(self):
        return Documento.objects.filter(categoria__iexact='electronica')

class DocumentoDView(ListView):
    model = Documento
    template_name = 'lic_diseno.html'
    context_object_name = 'object_list'

    def get_queryset(self):
        return Documento.objects.filter(categoria__iexact='diseno')

class DocumentoTView(ListView):
    model = Documento
    template_name = 'lic_tecnologia.html'
    context_object_name = 'object_list'

    def get_queryset(self):
        return Documento.objects.filter(categoria__iexact='tecnologia')

class DocumentoDetailView(DetailView):
    model = Documento
    template_name = 'documento_detalle.html'

# ----------- EXTRACCI√ìN DE INFORMACI√ìN -----------

def extraer_texto(pdf_path):
    # Abrir el archivo PDF
    doc = fitz.open(pdf_path)
    num_paginas = len(doc)

    # Extraer el texto de cada p√°gina
    texto = ""
    for pagina in doc:
        texto += pagina.get_text()

    # Devolver el texto y el n√∫mero de p√°ginas
    return texto, num_paginas, pdf_path

def eliminar_tabla_contenido(doc):
    """
    Elimina p√°ginas desde que se detecta 'Tabla de contenido' o similar,
    y contin√∫a eliminando mientras m√°s del 30% de las l√≠neas contengan n√∫meros o numeraci√≥n tipo √≠ndice.
    """
    texto_total = ""
    eliminar = False
    saltando = False

    for i, pagina in enumerate(doc):
        texto_pagina = pagina.get_text()
        lineas = texto_pagina.splitlines()

        # üîπ Paso 1: detectar inicio del √≠ndice
        if not eliminar:
            if re.search(r"(?i)(TABLA\s+DE\s+CONTENIDO|√çndice\s+de\s+contenido|Contenido|Tabla\s+de\s+contenidos)", texto_pagina):
                eliminar = True
                saltando = True
                print(f"üìå Tabla de contenido detectada en p√°gina {i+1}, analizando siguientes p√°ginas...")
                continue

        # üîπ Paso 2: si estamos eliminando, revisar si esta p√°gina es √≠ndice (basado en numeraciones)
        if eliminar and saltando:
            total = len(lineas)
            if total == 0:
                continue

            numeradas = sum(
                1 for linea in lineas
                if re.match(r"\s*\d+(\.\d+)*\s+.+", linea)  # Ej: "1. Introducci√≥n", "3.4 Marco te√≥rico"
            )

            porcentaje = numeradas / total
            if porcentaje >= 0.3:
                print(f"üßπ P√°gina {i+1} eliminada (√≠ndice con {porcentaje:.0%} de l√≠neas numeradas)")
                continue  # Saltamos esta p√°gina
            else:
                saltando = False  # Ya no estamos en tabla de contenido

        # üîπ Paso 3: conservar el resto de las p√°ginas
        texto_total += texto_pagina

    return texto_total

# Esta funci√≥n intenta extraer el t√≠tulo de un texto (por ejemplo, el de un PDF convertido)
# Ignora encabezados t√≠picos y se detiene si encuentra el nombre del autor
def obtener_titulo(texto, nombre_autor=None):
    """
    Extrae el t√≠tulo tomando m√°ximo 10 l√≠neas desde el primer contenido √∫til
    e ignorando encabezados institucionales. Detiene la extracci√≥n si encuentra el nombre del autor.
    """
    # Divide el texto completo en l√≠neas
    lineas = texto.splitlines() 
    # Lista donde se ir√°n guardando las l√≠neas del posible t√≠tulo
    titulo_lineas = []
    # Contador para detectar si hay dos l√≠neas vac√≠as seguidas (lo cual indica posible final del t√≠tulo)
    lineas_vacias_seguidas = 0
    # Bandera para saber cu√°ndo empezar a considerar l√≠neas como parte del t√≠tulo
    ha_empezado = False
    # L√≠mite m√°ximo de l√≠neas a considerar como t√≠tulo
    max_lineas = 10    # Si se proporcion√≥ el nombre del autor, se normaliza para compararlo f√°cilmente
    autor_normalizado = normalizar(nombre_autor) if nombre_autor else None
    # Recorremos todas las l√≠neas del texto
    for linea in lineas:
        # Quitamos espacios al inicio y al final
        limpia = linea.strip()
        # Si la l√≠nea tiene palabras institucionales comunes, la ignoramos
        if any(pal in limpia.upper() for pal in [
            "UNIVERSIDAD PEDAG√ìGICA NACIONAL", "FACULTAD", "DEPARTAMENTO", "LICENCIATURA", "P√ÅGINA"
        ]):
            continue
        # Si a√∫n no hemos empezado y la l√≠nea est√° vac√≠a o solo tiene un n√∫mero o dice "p√°gina", la ignoramos
        if not ha_empezado and (not limpia or limpia.isdigit() or re.search(r'\|\s*P\s*a\s*g\s*e', limpia, re.IGNORECASE)):
            continue
        # Marcamos que ya empezamos a encontrar contenido √∫til
        ha_empezado = True
        # Si encontramos el nombre del autor, detenemos la extracci√≥n
        if autor_normalizado and autor_normalizado in normalizar(limpia):
            break
        # Si la l√≠nea est√° vac√≠a, aumentamos el contador de vac√≠as seguidas
        if not limpia:
            lineas_vacias_seguidas += 1
            # Si hay 2 vac√≠as seguidas, probablemente se acab√≥ el bloque del t√≠tulo
            if lineas_vacias_seguidas >= 2:
                break
            continue
        else:
            # Si no est√° vac√≠a, reiniciamos el contador
            lineas_vacias_seguidas = 0
        # Si la l√≠nea tiene solo un n√∫mero o es una marca de p√°gina, la ignoramos
        if limpia.isdigit() or re.search(r'\|\s*P\s*a\s*g\s*e', limpia, re.IGNORECASE):
            continue
        # Agregamos esta l√≠nea como parte del posible t√≠tulo
        titulo_lineas.append(limpia)
        # Si ya tenemos suficientes l√≠neas (10), paramos
        if len(titulo_lineas) >= max_lineas:
            break
    # Unimos todas las l√≠neas del t√≠tulo en una sola cadena
    titulo = ' '.join(titulo_lineas)  
    # Eliminamos espacios m√∫ltiples entre palabras
    titulo = re.sub(r'\s{2,}', ' ', titulo).strip()
    # Si se encontr√≥ un t√≠tulo, lo devolvemos; si no, devolvemos None
    return titulo if titulo else None

#lista de apellidos 
APELLIDOS_COMUNES = [
    "Abella", "Acevedo", "Aldana", "Ardila", "Ariza", "Arias", "Acosta", "Barahona", "Barrera", "Beltr√°n", "Ben√≠tez", "Boh√≥rquez","Bossa", "Bustamante","Buitrago",
    "Cano", "C√°rdenas", "Cely", "Casallas", "Castillo", "Castro", "Chac√≥n", "Cifuentes", "Cordero", "Cort√©s","Cocunubo", "Corredor", "D√≠az", "Duarte", "Estupi√±√°n", 
    "Escobar", "Fayad", "Florez","Garc√≠a", "Garcia", "G√≥mez", "Gonz√°lez", "Guataqu√≠", "Guerrero", "Guti√©rrez", "Hern√°ndez", "Jim√©nez", "Leiva", "Lopera", "L√≥pez",
    "Lozano", "Mahecha", "Maldonado", "Malag√≥n", "Marroqu√≠n", "Mar√≠n", "Martin", "Mart√≠nez", "Medina", "Merchan", "Merch√°n", "Montero", "Monsalve", "More", "Moreno", 
    "Murillo", "Ordo√±ez","Oviedo", "Ot√°lora", "Pati√±o", "Pe√±a", "Perdomo", "Perez", "Pereira", "Pilar", "Pinz√≥n", "Poveda", "Prieto", "Quintero", "Ram√≠rez", "Reyes", 
    "Rivera", "Roberto", "Rodr√≠guez", "Rojas","Romero", "Rua", "Rinc√≥n", "Rueda", "Salazar", "S√°nchez","Sandoval", "Sarmiento","Sanabria", "Suarez", "Su√°rez", "Torres",
    "T√©llez", "Terreros", "Urue√±a", "Valero", "Vargas", "Vega", "Velandia", "Vel√°squez","Valencia","Zamora"
]


def detectar_nombres_por_apellidos(texto, apellidos_comunes):
    etiquetas = [
        "autor(es):", "autor:", "presentado por:", "asesor:", "asesora:",
        "asesor", "asesora", "director:", "tutor:", "elaborado por:",
        "docente:", "nombre:","directora:", "dirigido por:", "profesor:"
    ]
    palabras_prohibidas = [
        "cedid", "institucion", "instituci√≥n", "instituci√≥n educativa", "colegio",
        "tecnolog√≠a en"
    ]
    nombres_detectados = []
    linea_anterior = ""

    for linea in texto.splitlines():
        linea_original = linea.strip()

        # Si la l√≠nea anterior contiene palabras prohibidas, no procesar esta
        if any(p in linea_anterior.lower() for p in palabras_prohibidas):
            linea_anterior = linea  # actualizar igual
            continue
        # Si esta l√≠nea contiene palabras prohibidas, tambi√©n se descarta
        if any(p in linea_original.lower() for p in palabras_prohibidas):
            linea_anterior = linea  # actualizar
            continue
        # Ahora s√≠: limpiar y procesar
        linea_limpia = linea_original.lower()
        for etiqueta in etiquetas:
            linea_limpia = linea_limpia.replace(etiqueta, "")
        # Separar si hay m√∫ltiples nombres
        posibles_nombres = re.split(r"/|,| y ", linea_limpia)
        for nombre in posibles_nombres:
            nombre_candidato = " ".join(p.capitalize() for p in nombre.strip().split())
            if (
                any(ap.lower() in nombre_candidato.lower() for ap in apellidos_comunes)
                and len(nombre_candidato.split()) <= 5
                and not re.search(r"\b[\w\.-]+@[\w\.-]+\.\w+\b", nombre_candidato)
            ):
                if nombre_candidato not in nombres_detectados:
                    nombres_detectados.append(nombre_candidato)
        linea_anterior = linea  # actualizar para la pr√≥xima vuelta

    return nombres_detectados

def es_nombre_valido(texto):
    texto = texto.lower()
    palabras_prohibidas = [
        "gracias", "agradezco", "agradecimiento", "felicito", "mira", "dedico",  
        "abuelo", "abuela", "mam√°", "maestro", "maestra",                        
        "padres", "madre", "padre", "cuidados", "esposa", "esposo",              
        "profesor", "familia", "cedid", "institucion", "instituci√≥n", 
        "instituci√≥n educativa", "colegio"                                                    
    ]
    return not any(p in texto for p in palabras_prohibidas)

def detectar_a√±o(texto):
    """
    Busca un a√±o que comience con '20' (ej: 2015, 2020, 2023) en el texto.
    Retorna el primer a√±o encontrado o None si no hay coincidencias.
    """
    coincidencias = re.findall(r"\b(20\d{2})\b", texto)
    return coincidencias[0] if coincidencias else None

def extraer_info_sin_formato_rae(texto, num_paginas, ruta_pdf):
    """Extrae informaci√≥n clave si el documento no tiene formato RAE."""
    #Primeras paginas
    doc = fitz.open(ruta_pdf)
    primeras_paginas = ""
    paginas_leidas = 0
    i = 0

    while paginas_leidas < 2 and i < len(doc):
        contenido = doc[i].get_text().strip()
        if contenido:  # Si no est√° vac√≠a
            primeras_paginas += contenido + "\n"
            paginas_leidas += 1
        i += 1

    info = {
        "T√çTULO": "No encontrado",
        "AUTOR(ES)": "No encontrado",
        "DIRECTOR": "No encontrado",
        "PALABRAS CLAVE": "No disponibles",
        "UNIDAD PATROCINANTE": "Universidad Pedag√≥gica Nacional",
        "PUBLICACI√ìN": "No disponible",
        
    }
    # Si no se encontr√≥ t√≠tulo, usar el nombre del archivo como fallback
    info["T√çTULO"] = obtener_titulo(texto)
    # Buscar AUTOR
    if info["AUTOR(ES)"] == "No encontrado":
        posibles_nombres = detectar_nombres_por_apellidos(primeras_paginas, APELLIDOS_COMUNES)
    
        vistos = set()
        nombres_unicos = []
    
        for nombre in posibles_nombres:
            if nombre not in vistos and es_nombre_valido(nombre):  # <- asumes que ya tienes esta funci√≥n
                vistos.add(nombre)
                nombres_unicos.append(nombre)
            if len(nombres_unicos) == 3:
                break
    
        if nombres_unicos:
            if len(nombres_unicos) == 1:
                info["AUTOR(ES)"] = nombres_unicos[0]
            elif len(nombres_unicos) == 2:
                info["AUTOR(ES)"] = nombres_unicos[0]
                info["DIRECTOR"] = nombres_unicos[1]
            elif len(nombres_unicos) == 3:
                info["AUTOR(ES)"] = f"{nombres_unicos[0]} /\n {nombres_unicos[1]}"
                info["DIRECTOR"] = nombres_unicos[2]

    nombre_para_titulo = nombres_unicos[0] if nombres_unicos else None
    info["T√çTULO"] = obtener_titulo(texto, nombre_para_titulo)
    # Buscar FECHA
    a√±o = detectar_a√±o(primeras_paginas)
    if a√±o:
        info["PUBLICACI√ìN"] = f"Bogot√°. Universidad Pedag√≥gica Nacional, {a√±o}. {num_paginas}p."
    else:
        info["PUBLICACI√ìN"] = f"Bogot√°. Universidad Pedag√≥gica Nacional. {num_paginas}p."

    return info

def extraer_descripcion(texto, cierres):
    contenido_dec = ""
    for cierre in cierres:
        matches = list(re.finditer(
            rf"\s*(\d+\s*\.\s*)?(Introducci[o√≥]n|INTRODUCCI[O√ì]N|Introducci[o√≥]n\s*y\s*aspectos\s0*generales|CAP[I√å]TULO I|Resumen|RESUMEN|Resumen\.|Resumen\s*Ejecutivo)\s*\n([\s\S]*?){cierre}",
            texto,  
            re.MULTILINE | re.DOTALL
        ))

        for match in matches:
            posible_contenido = match.group(3).strip()
            lineas = posible_contenido.splitlines()

            if lineas and (
                re.match(r"^\s*\d+\s*$", lineas[0]) and int(lineas[0]) >= 2
                or lineas[0].lower().startswith("xvii")
            ):
                continue

            lineas_numeradas = sum(
                1 for l in lineas if re.match(r"^\s*(\d+\.){1,3}\s*", l)
            )
            if lineas_numeradas / max(1, len(lineas)) > 0.4:
                continue

            if sum(1 for c in posible_contenido if c == '.') / max(1, len(posible_contenido)) > 0.2:
                continue

            contenido_dec = posible_contenido
            break

    if contenido_dec:
        parrafos = re.split(r'\n+\s*\n+', contenido_dec)
        parrafos_largos = [
            re.sub(r'\s+', ' ', p).strip()
            for p in parrafos
            if len(p.split()) > 50
        ]

        if len(parrafos_largos) >= 2:
            return '\n\n'.join(parrafos_largos[:2])
        elif parrafos_largos:
            return parrafos_largos[0]
        else:
            return re.sub(r'\s+', ' ', contenido_dec).strip()

    return "No encontrado"

def extraer_fuentes(texto):
    matches_f = re.finditer(
        r"\s*(\d+[\.\s]*)?"
        r"(Referencias|REFERENCIAS|Bibliograf[i√≠]a|BIBLIOGRAF√çA|Bibliogr[a√°√Å]ficos|Referencias\s*bibliogr√°ficas|Referencias\s*Bibliogr√°ficas|Referencias\s*Bibliogr√°ficas\s*:|REFERENCIAS\s*BIBLIOGR√ÅFICAS|BIBLIOGR√ÅFICOS)"
        r"\s*\n+(?!\s*\d\.\d)"
        r"([\s\S]*?)(?=(Anexo|Anexos|ANEXOS|INDICE|Listas|Ap[e√©√â]ndice\sA|Tabla\s*de\s*Im√°genes|Plan\s*de\s*trabajo\s*semanal|Contenido|\Z)\s*$)",
        texto,
        re.MULTILINE | re.DOTALL
    )

    fuente_final = ""

    for match in matches_f:
        posible_fuente = match.group(3).strip()

        # Verifica si contiene al menos una cita con a√±o (ej. (2020))
        if not re.search(r'\(\d{4}', posible_fuente):
            continue

        # Limpieza l√≠nea por l√≠nea, conservando contenido √∫til
        lineas_fuente = [
            re.sub(r'\s+', ' ', linea).strip()
            for linea in posible_fuente.splitlines()
            if len(linea.strip()) > 10
        ]

        if lineas_fuente:
            texto_fuente = '\n'.join(lineas_fuente).strip()

            # Limitar a 1000 palabras
            palabras = texto_fuente.split()
            if len(palabras) > 1000:
                palabras = palabras[:1000]
            fuente_final = ' '.join(palabras)
            return fuente_final

    return ""


# Funci√≥n para extraer las palabras m√°s frecuentes ignorando conectores
def extraer_palabras_clave(titulo, descripcion, metodologia, cantidad=7):
    # Unificar todo el contenido en un solo bloque de texto
    texto = f"{titulo} {descripcion} {metodologia}".lower()

    #  Diccionario de palabras que queremos excluir
    stopwords = {
        'la', 'el', 'los', 'las', 'de', 'del', 'en', 'y', 'a', 'que', 'un', 'una',
        'es', 'se', 'por', 'para', 'con', 'como', 'su', 'al', 'lo', 'sus', 'le',
        'o', 'm√°s', 'pero', 'no', 'ni', 'porque', 'cuando', 'donde', 'sobre', 'ya',
        'cual', 'cu√°l', 'qu√©', 'puede', 'mismo', 'cada', 'otros', 'otras', 'parte',
        'tiene', 'ser', 'estar', 'siendo', 'desde', 'trabajo', 'estudio', 'investigaci√≥n',
        'proceso', 'desarrollo', 'proyecto', 'educaci√≥n', 'educativa', 'tema', 'aspectos',
        'forma', 'caso', 'nuevo', 'nueva', 'an√°lisis', 'informaci√≥n', 'grado',
        'estrategia', 'tecnolog√≠as', 'comunicaci√≥n', 'tic', 'nueva', 'd√©cimo',
        'und√©cimo', 'primero', 'segundo', 'tercero', 'cuarto', 'quinto', 'sexto',
        's√©ptimo', 'octavo', 'noveno', 'once', 'doce', 'b√°sico', 'media', 'mayor',
        'menor', 'actual', 'primaria', 'secundaria', 'niveles', 'atenci√≥n',
        'colegio', 'escolar', 'universidad', 'instituci√≥n', 'estancia', 'educativo',
        'acad√©mico', 'sede', 'docente', 'docentes', 'estudiante', 'estudiantes',
        'profesor', 'profesores', 'ltda', 's.a.', 'cia', 'compa√±√≠a', 'sociedad',
        'empresa', 'ejemplo', 'uso', 'realizaci√≥n', 'finalidad', 'prop√≥sito',
        'objetivo', 'contexto', 'modo', 'manera', 'medio', 'nivel', '√°mbito',
        'campo', 'forma', 'mediada', 'moderar', 'funci√≥n', 'propuesta', 'presente',
        'nace', 'pedag√≥gica', 'fin', 'nacional', 'cargas', 'estresoras', 'producen',
        'elementos', 'considerar', 'informe', 'club', 'social', 'proyecci√≥n',
        'informativa', 'consolidar', 'escenario', 'teniendo', 'pr√°ctico', 'formaci√≥n'
        'est√°', 'proyectado', 'actividades', 'desarrollen', 'habilidades' ,'ejemplos',
        'algunas','etapa','personas','leal','esta','personas','grupo','siguiente',
        'brindar','necesidad','coherencia','trav√©s','cuales','implican','permiten',
        'utilizado','combinaci√≥n','√°rea','este', 'diferentes','asignatura','din√°mica',
        'basado', 'b√°sica','respuestas','fundamentaci√≥n', 't√≠tulo','estructuraci√≥n',
        'formaci√≥n','productivo','vereda','actividad','encontrado','hemos','muchas',
        'fase','documento','busca','buscar','unidad','analog√≠as','figura','partir',
        'recorrido','ello','realiz√≥','tipo','plantear','licenciatura','cabo','encuentran',
        'descritas','abordamos','espec√≠fico','taller','aplicadas','revisi√≥n','muestra',
        'roles','participaci√≥n','est√°','genere'
    }

    #  Extraer solo palabras de 3 o m√°s letras
    palabras = re.findall(r'\b[a-z√°√©√≠√≥√∫√±]{4,}\b', texto)
    # Filtrar por palabras no incluidas en stopwords
    palabras_filtradas = [p for p in palabras if p not in stopwords]
    # Contar frecuencia
    contador = Counter(palabras_filtradas)

    # Obtener las m√°s comunes
    palabras_clave = [palabra for palabra, _ in contador.most_common(cantidad)]

    return ', '.join(palabras_clave) if palabras_clave else "No disponibles"

def extraer_contenidos(texto):
    """
    Extrae la secci√≥n de Contenidos a partir de un encabezado com√∫n (√≠ndice, tabla de contenido, etc.)
    y devuelve una lista numerada limpia.
    """
    import re
    # Buscar encabezado entre m√∫ltiples variantes
    encabezado_patron = re.compile(
        r'\b(Tabla\s*de\s*contenido|√çndice\s*de\s*contenido|Tabla\s+de\s+Contenidos|Contenido|√çNDICE|TABLA\s*DE\s*CONTENIDO)\b',
        re.IGNORECASE
    )
    match = encabezado_patron.search(texto)
    if not match:
        return "No encontrado (no se encontr√≥ encabezado de contenido)"

    # Obtener texto desde el final del encabezado
    inicio = match.end()
    texto_restante = texto[inicio:]

    # Separar en l√≠neas no vac√≠as
    lineas = texto_restante.splitlines()
    lineas_utiles = [l.strip() for l in lineas if l.strip()]

    # Tomar las primeras 40 l√≠neas √∫tiles
    posibles_contenidos = lineas_utiles[:40]

    # Limpiar y filtrar l√≠neas
    elementos = []
    for linea in posibles_contenidos:
        linea = re.sub(r'[\.¬∑‚Ä¢‚Ä¶\-_]{3,}', '', linea)  # quitar puntos suspensivos y similares
        linea = re.sub(r'\s+', ' ', linea)  # normalizar espacios
        linea = re.sub(r'^\d+(\.\d+)*\s*', '', linea)  # quitar numeraciones tipo 1.1
        linea = linea.strip()
        if len(linea) > 2:
            elementos.append(linea)

    # Quitar duplicados manteniendo el orden
    vistos = set()
    final = []
    for e in elementos:
        clave = e.lower()
        if clave not in vistos:
            vistos.add(clave)
            final.append(e)

    if not final:
        return "No encontrado (contenido vac√≠o tras el encabezado)"

    return "\n".join(f"{i+1}. {elem}" for i, elem in enumerate(final))

def extraer_metodologia(texto, cierres):
    candidatos = []
    for cierre in cierres:
        pattern = re.finditer(
            rf"""
            \s*
            (\d+\s*\.\s*)?[\s\n]*
            (
                Metodolog[√≠i]a\.? |
                METODOLOG[I√ç]A |
                Dise√±o\s[Mm]etodol[o√≥]gico|
                Marco\smetodol[o√≥√ì]gico|
                Marco\sMetodol[o√≥√ì]gico|
                MARCO\s*METODOL[O√ì]GICO|
                Aspectos\s+Metodol[o√≥√ì]gicos |
                ASPECTOS\sMETODOL[O√ì]GICOS |
                Marco\s+procedimental |
                Metodolog[√≠i√çI]a\s+de\s+la\s+sesi[o√≥√ì]n |
                ejercicios\spropuestos |
                Design\sThinking |
                Dise√±o\s*de\s*investigaci√≥n|
                Plan\sDe\sTrabajo |
                PLAN\sDE\sTRABAJO |
                Cap√≠tulo\sI\:\sContextualizaci[o√≥]n |
                Gu√≠as\sy\sTalleres\sSTEM |
                Metodolog√≠a\spara\srecolecci√≥n\sde\sdatos\sde\sp√©rdidas |
                Enfoque\s*y\s*Metodolog√≠a\s*investigaci√≥n\. |
                METODOLOG√çA\s*DE\s*DISE√ëO|
                Metodolog√≠a\s*de\s*Desarrollo\s*de\s*software\s*RUP
            )

             \s*\n([\s\S]*?){cierre}""",
            texto,
            re.MULTILINE | re.DOTALL | re.VERBOSE
        )

        for match in pattern:
            posible_contenido = match.group(3).strip()
            lineas = posible_contenido.splitlines()

            if lineas:
                primera = lineas[0].strip()
                if re.fullmatch(r"\d+(\.\d+)*", primera):
                    continue
                if re.match(r"^\d+(\.\d+)*\s+[A-Z√Å√â√ç√ì√ö√ëa-z√°√©√≠√≥√∫√±]{1,10}$", primera):
                    continue

            if 10 < len(posible_contenido.split()) < 1000:
                candidatos.append(posible_contenido)

    if candidatos:
        mejor = max(candidatos, key=len)
        parrafos = re.split(r'\n\s*\n', mejor)
        parrafos_largos = [
            re.sub(r'\s+', ' ', p).strip()
            for p in parrafos
            if len(p.split()) > 40
        ]

        if len(parrafos_largos) >= 2:
            return '\n\n'.join(parrafos_largos[:2])
        elif parrafos_largos:
            return parrafos_largos[0]
        else:
            return re.sub(r'\s+', ' ', mejor).strip()

    return "No encontrado"

def extraer_conclusiones(texto, cierres):
    candidatos = []

    for cierre in cierres:
        pattern_conc = re.finditer(
            r"\s*(\d+\s*\.\s*\d*\s*)?"
            r"(Conclusiones|Conclusi[o√≥]n|CONCLUSIONES|CONCLUSIONES\.|CONCLUSI[O√ì]N|Conclusiones\s*y\s*recomendaciones)"
            rf"\s*[\n\.]*([\s\S]*?){cierre}",
            texto,
            re.MULTILINE | re.DOTALL
        )

        for match in pattern_conc:
            posible_contenido = match.group(3).strip()
            lineas = posible_contenido.splitlines()

            if lineas:
                primera = lineas[0].strip()
                if re.fullmatch(r"\d+(\.\d+)*", primera):
                    continue
                if re.match(r"^\d+(\.\d+)*\s+[A-Z√Å√â√ç√ì√ö√ëa-z√°√©√≠√≥√∫√±]{1,10}$", primera):
                    continue

            palabras = posible_contenido.split()
            indice_punto = next((i for i, p in enumerate(palabras) if '.' in p), None)
            if indice_punto is not None and indice_punto < 5:
                continue

            if 10 < len(palabras) < 1000:
                if any(
                    palabra in posible_contenido.lower().split('\n')[0]
                    for palabra in ["bibliograf√≠a", "referencias", 'recomendaciones']
                ):
                    continue
                if sum(1 for c in posible_contenido if c in ".¬∑‚Ä¢") / max(1, len(posible_contenido)) > 0.3:
                    continue

                candidatos.append(posible_contenido)

    if candidatos:
        mejor = max(candidatos, key=len)
        parrafos = re.split(r'\n\s*\n', mejor)
        parrafos_largos = [
            re.sub(r'\s+', ' ', p).strip()
            for p in parrafos
            if len(p.split()) > 10
        ]

        if len(parrafos_largos) >= 2:
            return '\n\n'.join(parrafos_largos[:2])
        elif parrafos_largos:
            return parrafos_largos[0]
        else:
            return re.sub(r'\s+', ' ', mejor).strip()

    return "No encontrado"

def extraer_secciones_sin_formato_rae(texto, num_paginas, ruta_pdf):
    # Abrimos el documento
    doc = fitz.open(ruta_pdf)

    # 1. Extraer CONTENIDOS antes de eliminar la tabla
    contenidos = extraer_contenidos(texto)

    # 2. Eliminar tabla de contenido directamente desde el documento
    texto = eliminar_tabla_contenido(doc)

    # 3. Limpiar numeraciones sueltas (despu√©s de eliminar tabla)
    texto = re.sub(r'\n\s*\d+\s*\n', '', texto)

    cierres = [
        r"(?=\n\s*\n)",         # Coincidencia por doble salto de l√≠nea
        r"(?=\.\s*\n)"          # Coincidencia por punto seguido de salto de l√≠nea
    ]

    # 4. Extraer otras secciones con el texto limpio
    secciones = {
        "Informaci√≥n General": extraer_info_sin_formato_rae(texto, num_paginas, ruta_pdf),
        "Descripci√≥n": extraer_descripcion(texto, cierres),
        "Fuentes": extraer_fuentes(texto) or "No encontrado",
        "Contenidos": contenidos,
        "Metodolog√≠a": extraer_metodologia(texto, cierres),
        "Conclusiones": extraer_conclusiones(texto, cierres)
    }

    # 5. Palabras clave inferidas con base en otras secciones
    info_general = secciones.get("Informaci√≥n General", {})
    titulo = info_general.get("T√çTULO", "")
    descripcion = secciones["Descripci√≥n"]
    metodologia = secciones["Metodolog√≠a"]
    info_general["PALABRAS CLAVE"] = extraer_palabras_clave(titulo, descripcion, metodologia)

    return secciones


    
def extraer_palabras_c(texto):
    patron = re.compile(
        r"(?i)Palabras(?:\s+Claves?)?\s*:?\s*\n*([\s\S]{0,400})"
    )
    coincidencia = patron.search(texto)
    if not coincidencia:
        return None

    seccion = coincidencia.group(1)
    lineas = seccion.strip().splitlines()
    palabras_clave = []

    for linea in lineas:
        linea = linea.strip()
        if not linea:
            continue

        # Detenerse si hay un n√∫mero (por seguridad)
        if re.search(r"\b\d+\b", linea):
            break

        # Separar por punto y coma o por coma
        if ';' in linea:
            palabras = [p.strip() for p in linea.split(';') if p.strip()]
            palabras_clave.extend(palabras)
        elif ',' in linea:
            palabras = [p.strip() for p in linea.split(',') if p.strip()]
            palabras_clave.extend(palabras)
        else:
            # Si no hay separador y hay m√°s de 3 palabras, se asume que no es parte de palabras clave
            if len(linea.split()) > 3:
                break
            palabras_clave.append(linea)

    return ', '.join(palabras_clave).strip() if palabras_clave else None

def extraer_titulo_rae(texto):
    patron = re.compile(
        r"(?i)T[√≠i]tulo\s+del\s+documento\s*:?\s*\n*(.+?)(?=\n\s*(AUTOR\(ES\)|AUTOR|DIRECTOR|INFORMACI√ìN GENERAL|PALABRAS CLAVE|FECHA DE PUBLICACI√ìN))",
        re.DOTALL
    )
    match = patron.search(texto)
    if match:
        titulo = match.group(1)
        # Limpiar saltos de l√≠nea y espacios
        return " ".join(titulo.strip().splitlines()).strip()
    return None

def extraer_info_general(texto):
    """ Extrae la informaci√≥n general sin mezclar datos. """
    info = {
        "T√çTULO": "No encontrado",
        "AUTOR(ES)": "No encontrado",
        "DIRECTOR": "No registrado",
        "PALABRAS CLAVE": "No disponibles",
        "UNIDAD PATROCINANTE": "No disponible",
        "PUBLICACI√ìN": "No disponible",
    }

    # Extraer t√≠tulo (tomando hasta 6 l√≠neas para evitar truncamientos)
    titulo = extraer_titulo_rae(texto)
    if titulo:
        info["T√çTULO"] = titulo

    match_info_general = re.search(r"(?i)Informaci√≥n General\s*(.*)", texto, re.DOTALL)
    if match_info_general:
        texto_info_general = match_info_general.group(1)

        # Aplicar patrones individuales (excepto palabras clave)
        patrones = {
            "AUTOR(ES)": r"(?is)autor(?:\(es\))?\s*:?\s*(.*?)\s*(?:director|tutor|jurado|asesor)",
            "DIRECTOR": r"(?i)director\s*:?\s*\n*([^\n]+)",
            "UNIDAD PATROCINANTE": r"(?i)unidad\s*\n*patrocinante\s*:?\s*(.+)",
            "PUBLICACI√ìN": r"(?i)publicaci[o√≥]n\s*:?\s*(.*?)(?=\n\s*unidad\s*\n*patrocinante)"
        }

        for clave, patron in patrones.items():
            match = re.search(patron, texto_info_general)
            if match:
                info[clave] = match.group(1).strip()

        # Usar funci√≥n especializada para palabras clave
        palabras_clave = extraer_palabras_c(texto_info_general)
        if palabras_clave:
            info["PALABRAS CLAVE"] = palabras_clave

    return info

def extraer_secciones(texto, num_paginas):
    """ Extrae las secciones del documento. """
    secciones = {
        "Informaci√≥n General": extraer_info_general(texto),
        "Descripci√≥n": "No encontrado",
        "Fuentes": [],
        "Contenidos": "No encontrado",
        "Metodolog√≠a": "No encontrado",
        "Conclusiones": "No encontrado"
    }

    patrones = {
        "Descripci√≥n": r"(?i)(?:1|2)\.\s*Descripci[o√≥]n\s*(.*?)(?=\n\d+\.\s|\Z)",
        "Metodolog√≠a": r"(?i)(?:4|5)\.\s*Metodolog√≠a\s*(.*?)(?=\n\d+\.\s|\Z)",
        # Usamos grupo no capturante (?:...) para que solo capture el contenido real
        "Conclusiones": r"(?i)(?:5|6)\.\s*(?:Conclusi√≥n|Conclusiones)\s*(.*?)(?=\n(?:Elaborado por|Revisado por|Bibliograf√≠a|Referencias|\Z))",
        "Contenidos": r"(?i)(?:4|3)\.\s*Contenidos\s*:?\s*\n*([\s\S]+?)(?=\n5\.)",
    }

    for seccion, patron in patrones.items():
        match = re.search(patron, texto, re.DOTALL)
        if match:
            contenido = match.group(1).strip()
            # Solo limpiar saltos de l√≠nea en las secciones textuales
            if seccion != "Contenidos":
                contenido = re.sub(r'\n+', ' ', contenido)
            contenido = limpiar_encabezados(contenido)
            secciones[seccion] = contenido

    # Extraer fuentes como lista
    fuentes_match = re.search(r"(?i)(?:2|3)\.\s*(Fuentes|Bibliograf√≠a)\s*([\n\s\S]+?)(?=\n\d+\.\s|\Z)", texto, re.DOTALL)
    if fuentes_match:
        lineas = fuentes_match.group(2).strip().split("\n")
        secciones["Fuentes"] = [line.strip() for line in lineas if line.strip()]
    
    return secciones

def limpiar_encabezados(texto):
    """Elimina encabezados innecesarios y limpia el texto."""
    patrones_excluir = [
        r"(?i)contenido\s*\d+",  
        r"(?i)FORMATO\s+RESUMEN\s+ANAL√çTICO\s+EN\s+EDUCACI√ìN\s+-\s+RAE",  
        r"(?i)C√≥digo:\s*FOR\d+\w*",  
        r"(?i)Versi√≥n:\s*\d+",  
        r"(?i)Fecha de Aprobaci√≥n:\s*\d{2}-\d{2}-\d{4}",  
        r"(?i)P√°gina\s*\d+\s*de\s*\d+",  
    ]
    
    for patron in patrones_excluir:
        texto = re.sub(patron, "", texto)

    # ‚úÖ Elimina l√≠neas vac√≠as y espacios extra
    texto = "\n".join([line.strip() for line in texto.split("\n") if line.strip()])

    return texto.strip()

def procesar_documento(path_pdf):
    texto, num_paginas, ruta_pdf = extraer_texto(path_pdf)

    # Verificar si tiene formato RAE directamente por las frases clave
    if (re.search(r"Tipo\s*de\s*documento", texto, re.IGNORECASE) and
        re.search(r"Acceso\s*al\s*documento", texto, re.IGNORECASE) and
        re.search(r"T[i√≠]tulo\s*del\s*documento", texto, re.IGNORECASE)):
        
        print("‚úÖ Documento con formato RAE detectado.")
        info_general = extraer_info_general(texto)
        secciones = extraer_secciones(texto, num_paginas)
    else:
        print("‚ö†Ô∏è Documento posiblemente sin formato RAE. Aplicando extractor alternativo.")
        info_general = extraer_info_sin_formato_rae(texto, num_paginas, path_pdf)
        secciones = extraer_secciones_sin_formato_rae(texto, num_paginas, path_pdf)

    info_general = info_general or {}
    secciones = secciones or {}

    return {**info_general, **secciones}